
---
title: "Experiments W2V VS BERT"
output:
  pdf_document: default
  html_notebook: default
---



```{r, echo = FALSE}
library("reticulate")
library("data.table")
library("ggplot2")

root_folder <- "C:/Users/scordoba/sync/projects/proj-nlp/"


# loading data
FILE_PY_READ_PICKLE <- paste0(root_folder, "app/lib/py/reader/read_pickle.py")
source_python(FILE_PY_READ_PICKLE)

FILE_PKL_TO_READ_SIM <- paste0(root_folder, "data/exchange/ws353_input_sim")
FILE_PKL_TO_READ_W2V_WORDS <- paste0(root_folder, "data/exchange/ws353_w2v_words_context")
FILE_PKL_TO_READ_BERT_WORDS <- paste0(root_folder, "data/exchange/ws353_bert_words")
FILE_PKL_TO_READ_BERT_CONTEXT <- paste0(root_folder, "data/exchange/ws353_bert_words_context")

#### read dataframe from .pkl file
data_sim <- setDT(read_pickle_file(FILE_PKL_TO_READ_SIM))
data_w2v_words <- setDT(read_pickle_file(FILE_PKL_TO_READ_W2V_WORDS))
data_bert_words <- setDT(read_pickle_file(FILE_PKL_TO_READ_BERT_WORDS))

review_cols <- c("id", "w", "id_token", "token")

```

# test 1/2: W2V vs BERT - word to word (context)

## DATA

dataset with mannual annotation of similaraties between pairs of words (wordsim353);


```{r}
head(data_sim)

```


and dataset with vector representations (w2v) of the set of words appeared (we show only the first two dimensions);

```{r}
head(data_w2v_words[ , c(review_cols, "dim_1", "dim_2"), with = FALSE])

```

we select rows with equal w and token 

NOTE: w2v is context-free but we could test it.


Also, we have our BERT representations (free-context) in this way,

```{r}
head(data_bert_words[ , c(review_cols, "dim_w_1", "dim_w_2"), with = FALSE])
```



```{r echo=FALSE}
length(unique(data_w2v_words$w))
length(unique(data_bert_words$w))

df_vec_w2v <- subset(data_w2v_words[w == token], select = -c(id_token, token))
# head(df_vec_w2v)
# dim(df_vec_w2v)

df_vec_bert <- subset(data_bert_words, select = -c(id_token, token))
# head(df_vec_bert)
# dim(df_vec_bert)

####
#### ...remove words that aren't in both datasets...
df_vec_bert <- df_vec_bert[w %in% df_vec_w2v$w]


####
#### ...we test the words that exist in both datasets...
cols_w2v <- c("id", "w")
cols_bert <- c("id", "w")
df_join <- df_vec_w2v[df_vec_bert , , on = .(id, w)][ , c(cols_w2v, cols_bert), with = FALSE]
#head(df_join)
#df_join[ is.na(w), , ]
```


Firstly, we remove words that we haven't in both datasets (4 words are lost in w2v dataset because are out-of-vocabulary). 
Now, we can compute (cosine) similarities between vector representations (w2v and BERT) pairs of words in "data_sim" and compare with the mannual scoring. 


```{r, echo = FALSE}
get_vector_of_w <- function(df_vec, row = 1, col_vec_start = 3, col_vec_end = 302){
    return (sapply(col_vec_start:col_vec_end, function(d){as.numeric(df_vec[row, c(colnames(df_vec)[d]), with = FALSE])}))
}

compute_cosin <- function(a, b){
    cos_theta <- ( sum(a*b) / ( sqrt(sum(a * a)) * sqrt(sum(b * b)) ) )
    #theta <- acos( sum(a*b) / ( sqrt(sum(a * a)) * sqrt(sum(b * b)) ) )
    return (cos_theta)
}


w2v_vector_cosines <- sapply(1:nrow(data_sim), function(r){
    word1 <- as.character(data_sim[r, .(w1), ])
    word2 <- as.character(data_sim[r, .(w2), ])
    
    index_word1 <- which(df_vec_w2v$w == word1)
    index_word2 <- which(df_vec_w2v$w == word2)
    
    rep1 <- get_vector_of_w(df_vec_w2v, row = index_word1, col_vec_start = 3, col_vec_end = 302)
    rep2 <- get_vector_of_w(df_vec_w2v, row = index_word2, col_vec_start = 3, col_vec_end = 302)
    
    cosine <- compute_cosin(rep1, rep2)
    #print(paste0("computing words - ", word1, " and ", word2, " - ", cosine))
    
    return (cosine)
})


bert_vector_cosines <- sapply(1:nrow(data_sim), function(r){
    word1 <- as.character(data_sim[r, .(w1), ])
    word2 <- as.character(data_sim[r, .(w2), ])
    
    index_word1 <- which(df_vec_bert$w == word1)
    index_word2 <- which(df_vec_bert$w == word2)
    
    rep1 <- get_vector_of_w(df_vec_bert, row = index_word1, col_vec_start = 3, col_vec_end = 770)
    rep2 <- get_vector_of_w(df_vec_bert, row = index_word2, col_vec_start = 3, col_vec_end = 770)
    
    cosine <- compute_cosin(rep1, rep2)
    #print(paste0("computing words - ", word1, " and ", word2, " - ", cosine))
    
    return (cosine)
})


####
#### ...add the similarities to "data_sim" dataset...
data_sim$w2v_cosine <- w2v_vector_cosines
data_sim$bert_cosine <- bert_vector_cosines

head(data_sim)


####
#### save dataset
saveRDS(data_sim, file = paste0(root_folder, "data/exchange/20200112-test1/data_sim.rds"))
```


With this dataset we can compare mannual similarity with cosine metric for w2v and BERT representations.


## ANALYSIS

We clean NA puntuations, and we get 328 complete rows.


NOTE: we observe 3 values of cosine (w2v) < 0


```{r, echo = FALSE}
# read similarities dataset
#data_sim <- readRDS(file = paste0(root_folder, "data/exchange/20200112-test1/data_sim.rds"))
#head(data_sim)

# clean NA punctuations... we get complete rows..
data_sim <- na.omit(data_sim)

# ...we review cosine values...
data_sim[w2v_cosine < 0]
data_sim[bert_cosine < 0]
```




We can plot similarities scores,

```{r}
ggplot() + geom_line(aes(x = seq(1:length(data_sim$w1)), y = data_sim$w2v_cosine),color='red') + 
           geom_line(aes(x = seq(1:length(data_sim$w1)), y = data_sim$bert_cosine),color='blue') + 
           ylab('cosine similarity') + xlab('n_pair_of_words') + ggtitle("bert (free-context) vs w2v - word to word")

```

We can observe the best results for BERT representations.

Also we can compute the Pearson coefficient in both case respect to the mannual scores in dataset. For w2vec similarities,

```{r}
cor(data_sim$score, data_sim$w2v_cosine, method = c("pearson"))
```

and for BERT cosine similarities,

```{r}
cor(data_sim$score, data_sim$bert_cosine, method = c("pearson"))
```

We can observe highest similarity metric for BERT representations, but has a worst correlation with mannual scoring. 

And corrlation between both vector representations scoring is,

```{r}
cor(data_sim$w2v_cosine, data_sim$bert_cosine, method = c("pearson"))
```



### BERT non-free-context

Now, we can use the BERT vector representation of the same word got from word in a phrase (context).

In the next dataset we have a phrase containing the word and we have the vector representation got in this case,


```{r, echo = FALSE}
data_bert_words_context <- setDT(read_pickle_file(FILE_PKL_TO_READ_BERT_CONTEXT))

head(data_bert_words_context[ , c(review_cols, "dim_context_1", "dim_context_2"), with = FALSE])
```

and we select the corresponding vector,

```{r, echo = FALSE}
data_bert_words_context <- data_bert_words_context[w == token]
data_bert_words_context <- subset(data_bert_words_context, select = -c(id_token, token))

#### clean rows with NA values...
data_bert_words_context <- na.omit(data_bert_words_context)

head(data_bert_words_context[ , c("id", "w", "dim_context_1", "dim_context_2"), with = FALSE])
#dim(data_bert_words_context)
```


```{r, echo = FALSE}
bert_context_vector_cosines <- sapply(1:nrow(data_sim), function(r){
    word1 <- as.character(data_sim[r, .(w1), ])
    word2 <- as.character(data_sim[r, .(w2), ])
    
    index_word1 <- which(data_bert_words_context$w == word1)
    index_word2 <- which(data_bert_words_context$w == word2)
    
    rep1 <- get_vector_of_w(data_bert_words_context, row = index_word1, col_vec_start = 3, col_vec_end = 770)
    rep2 <- get_vector_of_w(data_bert_words_context, row = index_word2, col_vec_start = 3, col_vec_end = 770)
    
    cosine <- compute_cosin(rep1, rep2)
    #print(paste0("computing words - ", word1, " and ", word2, " - ", cosine))
    
    return (cosine)
})


####
#### ...add the similarities to "data_sim" dataset...
data_sim$bert_context_cosine <- bert_context_vector_cosines

head(data_sim)


####
#### save dataset
saveRDS(data_sim, file = paste0(root_folder, "data/exchange/20200112-test2/data_sim.rds"))
```


in this case the before results are,


```{r}
cor(data_sim$score, data_sim$bert_context_cosine, method = c("pearson"))
```

we can observe a bit improve respect to results with BERT free-context.


## BERT VS W2V


```{r, echo = FALSE}
data_sim <- readRDS(file = paste0(root_folder, "data/exchange/20200112-test2/data_sim.rds"))

head(data_sim, 30)

sum(ifelse(data_sim$bert_cosine > data_sim$w2v_cosine, 1, 0))/length(data_sim$bert_cosine)
```

In the 96 % of rows BERT win to W2V

```{r}
sum(ifelse(data_sim$bert_context_cosine > data_sim$w2v_cosine, 1, 0))/length(data_sim$bert_context_cosine)
```

WARNING!!! BERT free-context better than BERT with context???


We review cases with BERT with context better than BERT-free-context,

```{r}
data_sim[bert_cosine < bert_context_cosine]
```

We review the context (the length, in example) that we use with this words,

```{r}
words <- unique(data_sim[bert_cosine < bert_context_cosine]$w1, data_sim[bert_cosine < bert_context_cosine]$w2)
words
```

```{r}
data_bert_words_context <- setDT(read_pickle_file(FILE_PKL_TO_READ_BERT_CONTEXT))
data_bert_words_context <- data_bert_words_context[w %in% words]
table(data_bert_words_context[ , .(n = max(.SD$id_token)), by = .(w)]$n)

```

distribution with median (and more concentrated) between 6 - 8 words for context length. For all context used in tdataset, the length distribution is,

```{r}
data_bert_words_context <- setDT(read_pickle_file(FILE_PKL_TO_READ_BERT_CONTEXT))
data_bert_words_context <- data_bert_words_context[ , .(n = max(.SD$id_token)), by = .(w)]$n
table(data_bert_words_context)
median(data_bert_words_context)
```
It looks like words with bert-with-context vector representation is not too much associated to its context length.

WARNING!!! Neither assocciated to its context length????



# Appointment in clustering

```{r}

```

